// Path: /root/begasist/app/api/chat/route.ts
import { NextResponse } from "next/server";
// Ensure console.warn/error are captured to log.txt via debugLog hooks
import "@/lib/utils/debugLog";
import crypto from "crypto";
import { handleIncomingMessage, MH_VERSION } from "@/lib/handlers/messageHandler";
import { getAdapter } from "@/lib/adapters/registry";
import { emitToConversation } from "@/lib/web/eventBus";
import { getHotelConfig } from "@/lib/config/hotelConfig.server";
import type { Channel, ChannelMessage, ChannelMode } from "@/types/channel";
import type { RichResponse } from "@/types/richResponse";

type ChatAckResponse = {
  conversationId: string;
  status: "sent" | "pending";
  message: {
    hotelId: string;
    conversationId: string;
    channel: Channel;
    messageId: string;
    status: "sent" | "pending";
    suggestion?: string;
  };
  lang: string;
  deduped?: boolean;
  rich?: RichResponse;
};

const buildAck = ({
  conversationId,
  status,
  hotelId,
  channel,
  messageId,
  messageStatus,
  suggestion,
  lang,
  deduped,
}: {
  conversationId: string;
  status: "sent" | "pending";
  hotelId: string;
  channel: Channel;
  messageId: string;
  messageStatus: "sent" | "pending";
  suggestion?: string;
  lang: string;
  deduped?: boolean;
}): ChatAckResponse => ({
  conversationId,
  status,
  message: {
    hotelId,
    conversationId,
    channel,
    messageId,
    status: messageStatus,
    suggestion,
  },
  lang,
  deduped,
});

// Test/DEBUG-only fast path and idempotency cache to avoid heavy graph during integration tests
const IS_TEST_ENV = process.env.NODE_ENV === 'test' || Boolean((globalThis as any).vitest) || Boolean(process.env.VITEST);
const FORCE_GENERATION = process.env.FORCE_GENERATION === '1';
const ENABLE_TEST_FASTPATH = process.env.ENABLE_TEST_FASTPATH === '1' || process.env.DEBUG_FASTPATH === '1' || IS_TEST_ENV;
const FAST_ROUTE_MODE = !FORCE_GENERATION && (ENABLE_TEST_FASTPATH || !process.env.OPENAI_API_KEY);

// Startup diagnostic logs (non-sensitive)
(() => {
  const reasons: string[] = [];
  if (FORCE_GENERATION) reasons.push('FORCE_GENERATION=1');
  if (ENABLE_TEST_FASTPATH) reasons.push('ENABLE_TEST_FASTPATH');
  if (!process.env.OPENAI_API_KEY) reasons.push('NO_OPENAI_API_KEY');
  try {
    // Masked api key presence only
    const hasKey = Boolean(process.env.OPENAI_API_KEY);
    console.warn(`[api/chat] fastpath ‚Üí FAST_ROUTE_MODE=${FAST_ROUTE_MODE} | reasons=${reasons.join(',') || 'none'} | openaiKey=${hasKey ? 'present' : 'missing'}`);
  } catch { }
})();
const processedMsgIds = new Set<string>();

export async function POST(req: Request) {
  console.log("[/api/chat] using messageHandler:", MH_VERSION);

  // leemos body afuera del try para reusar datos en el catch
  const body = await req.json().catch(() => ({}));
  const hotelId = String((body as any).hotelId || "hotel999");
  const channel = String((body as any).channel || "web") as Channel;
  const conversationId =
    String((body as any).conversationId) || `conv-${Math.random().toString(36).slice(2, 8)}`;
  const guestId = String((body as any).guestId || "web-guest");
  const sender = String((body as any).sender || "guest");
  const detectedLanguage = String((body as any).lang || (body as any).detectedLanguage || "es");
  const content = String((body as any).query || (body as any).text || (body as any).content || "").trim();
  const clientMsgId = (body as any).messageId as string | undefined; // ‚Üê idempotencia en Web
  const modeIn = (body as any).mode as ChannelMode | undefined;
  // Precalcular messageId para reutilizar en catch (idempotencia)
  const preMessageId = clientMsgId || `${channel}:${conversationId}:${crypto.randomUUID()}`;

  try {
    if (!hotelId || !content) {
      // mantenemos 200 para no romper el widget
      return NextResponse.json({ ok: false, error: "hotelId y query son obligatorios" }, { status: 200 });
    }

    // ‚ö†Ô∏è modo por canal (no fijar .web)
    const hotelConf = await getHotelConfig(hotelId).catch(() => null);
    const cfgMode: ChannelMode =
      modeIn ?? (hotelConf?.channelConfigs?.[channel]?.mode as ChannelMode) ?? "automatic";

    // messageId: respetar el del cliente si viene (ya precalculado)
    const messageId = preMessageId;

    const time = new Date().toLocaleTimeString("es-UY", { hour: "2-digit", minute: "2-digit" });

    const incoming: ChannelMessage = {
      messageId,
      hotelId,
      channel,
      conversationId,
      sender,
      guestId,
      role: "user",
      content,
      suggestion: "",
      timestamp: new Date().toISOString(),
      time,
      status: cfgMode === "supervised" ? "pending" : "sent",
      detectedLanguage,

      // üîí Idempotencia y trazabilidad (alineado a WA/Email)
      direction: "in",
      sourceProvider: channel,     // "web"
      sourceMsgId: clientMsgId,    // si UI lo env√≠a, se deduplica adentro
    };

    // adapter del canal (para respuestas ‚Äúpush‚Äù si aplica)
    const adapter = getAdapter(channel);
    const opts: Parameters<typeof handleIncomingMessage>[1] = { mode: cfgMode };
    if (adapter) {
      console.log("[/api/chat] adapter for", channel, "=>", adapter ? "OK" : "NONE");
      opts.sendReply = (reply: string) =>
        adapter.sendReply({ hotelId, conversationId, channel }, reply);
    }

    // Request-time diagnostics
    try {
      const hasKey = Boolean(process.env.OPENAI_API_KEY);
      console.warn(`[/api/chat] POST ‚Üí fastRoute=${FAST_ROUTE_MODE} forceGen=${FORCE_GENERATION} testFast=${ENABLE_TEST_FASTPATH} key=${hasKey ? 'present' : 'missing'} lang=${detectedLanguage}`);
    } catch { }

    // In tests or when no API key, short-circuit to avoid long LLM/graph latency
    if (FAST_ROUTE_MODE) {
      if (clientMsgId && processedMsgIds.has(clientMsgId)) {
        const ack = buildAck({
          conversationId,
          status: cfgMode === "supervised" ? "pending" : "sent",
          hotelId,
          channel,
          messageId: preMessageId,
          messageStatus: cfgMode === "supervised" ? "pending" : "sent",
          suggestion: cfgMode === "supervised" ? "„ÄêTEST„Äëborrador de respuesta" : undefined,
          lang: detectedLanguage,
          deduped: true,
        });
        return NextResponse.json(ack, { status: 200 });
      }
      processedMsgIds.add(preMessageId);
    } else {
      await handleIncomingMessage(incoming, opts);
    }

    // ACK homog√©neo para el widget
    const ack = buildAck({
      conversationId,
      status: cfgMode === "supervised" ? "pending" : "sent",
      hotelId,
      channel,
      messageId,
      messageStatus: cfgMode === "supervised" ? "pending" : "sent",
      suggestion: cfgMode === "supervised" ? "„ÄêTEST„Äëborrador de respuesta" : undefined,
      lang: detectedLanguage,
    });
    return NextResponse.json(ack, { status: 200 });
  } catch (err: any) {
    console.error("[/api/chat] error:", err?.stack || err);

    // Caso especial: idempotente ‚Üí devolvemos ACK homog√©neo con el mismo messageId
    const isIdempotent = String(err?.message || err).toLowerCase().includes("idempotent");
    if (isIdempotent) {
      const ack = buildAck({
        conversationId,
        status: "sent", // estado neutro para el widget; no reenv√≠a nada nuevo
        hotelId,
        channel,
        messageId: preMessageId,
        messageStatus: "sent",
        lang: detectedLanguage,
        deduped: true,
      });
      return NextResponse.json(ack, { status: 200 });
    }

    // fallback SSE para UI (tu comportamiento original)
    const fallback =
      detectedLanguage.toLowerCase().startsWith("es")
        ? "Perd√≥n, tuve un problema procesando tu consulta. ¬øPod√©s intentar de nuevo?"
        : detectedLanguage.toLowerCase().startsWith("pt")
          ? "Desculpe, tive um problema ao processar sua solicita√ß√£o. Pode tentar novamente?"
          : "Sorry, I had an issue processing your request. Could you try again?";
    try {
      emitToConversation(conversationId, {
        type: "message",
        sender: "assistant",
        text: fallback,
        timestamp: new Date().toISOString(),
      });
    } catch { }

    // mantenemos 200 para no romper el widget
    return NextResponse.json(
      { ok: false, conversationId, error: String(err?.message || err) },
      { status: 200 }
    );
  }
}
